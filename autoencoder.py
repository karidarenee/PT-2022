# -*- coding: utf-8 -*-
"""Autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e9jhUokk8RBmgnl4DnxrFKBbuXdmO94-
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from keras import Sequential
from keras.layers import Input
from keras.layers import Flatten
from keras.layers import Reshape
from keras.layers import LSTM
from keras.layers import Dense
from keras.models import Model
from keras.layers import RepeatVector
from keras.layers import TimeDistributed
from keras.layers import LeakyReLU
from keras.utils.vis_utils import plot_model
from sklearn.preprocessing import MinMaxScaler

#from google.colab import files
#uploaded = files.upload()

#from google.colab import drive
#drive.mount('/content/drive')

samples = 15696
seq_length = 1300
vars = ["GRFx", "GRFy", "GRFz", "Mx", "My", "Mz", "COPx", "COPy"]

def read_data(var,samples, seq_length):
  dfx = pd.read_csv("/content/drive/MyDrive/ae_data/"+var+".csv", sep=",")[0:samples]
  dfx.set_index("ID", inplace=True)
  fx = dfx.to_numpy().astype(float)[:,0:seq_length]

  scaler = MinMaxScaler()
  scaler.fit(fx)
  sc = scaler.transform(fx)
  return sc

data = [read_data(var, samples, seq_length) for var in vars]


a = []
for i in range(samples):
    s = []
    for j in range(seq_length):
      l = []
      for k in range(len(data)):
        l.append(data[k][i,j])
      s.append(l)
    b = np.array(s)
    a.append(b)
c = np.array(a)

latent_dim = 100
class Autoencoder(Model):
  def __init__(self, latent_dim,seq_length):
    super(Autoencoder, self).__init__()
    self.latent_dim = latent_dim   
    self.encoder = Sequential([
      Flatten(),
      Dense(latent_dim),
      LeakyReLU(alpha=0.05)
    ])
    self.decoder = Sequential([
      Dense(seq_length*8),
      LeakyReLU(alpha=0.05),
      Reshape((seq_length, 8))
    ])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Autoencoder(latent_dim, seq_length)
autoencoder.compile(optimizer='adam', loss="mse")

autoencoder.fit(c, c, epochs=50, verbose=1)

pre = autoencoder.predict(c, verbose=1)

train_loss = np.mean(np.abs(pre - c), axis=1)

plt.hist(train_loss)
plt.xlabel("Train MAE loss")
plt.ylabel("No of samples")
plt.show()

anomalies = train_loss > 0.04
print("Number of anomaly samples: ", np.sum(anomalies))
u = np.where(anomalies)
print("Indices of anomaly samples: ", u)
print("Number of Unique anomaly samples: ", len(u))

'''
model2 = Model(inputs=model.inputs, outputs=model.layers[0].output)
model2.summary()
yhat3 = model2.predict(c[0:2])
print(yhat3.shape)
print(yhat3)
print(yhat2)
'''

p=3993
r = 0

plt.plot(c[p,:,0])
plt.plot(pre[p,:,0])
#plt.plot(np.mean(c[:,:,0],axis=0))
plt.show()

plt.plot(c[p,:,1])
plt.plot(pre[p,:,1])
#plt.plot(np.mean(c[:,:,1],axis=0))
plt.show()

plt.plot(c[p,:,2])
plt.plot(pre[p,:,2])
#plt.plot(np.mean(c[:,:,2],axis=0))
plt.show()

plt.plot(c[p,:,3])
plt.plot(pre[p,:,3])
#plt.plot(np.mean(c[:,:,3],axis=0))
plt.show()

plt.plot(c[p,:,4])
plt.plot(pre[p,:,4])
#plt.plot(np.mean(c[:,:,4],axis=0))
plt.show()

plt.plot(c[p,:,5])
plt.plot(pre[p,:,5])
#plt.plot(np.mean(c[:,:,5],axis=0))
plt.show()

plt.plot(c[p,:,6])
plt.plot(pre[p,:,6])
#plt.plot(np.mean(c[:,:,6],axis=0))
plt.show()

plt.plot(c[p,:,7])
plt.plot(pre[p,:,7])
#plt.plot(np.mean(c[:,:,7],axis=0))
plt.show()

"""**Functional PCA**"""

#!pip install scikit-fda

'''
import skfda
from skfda.exploratory.visualization import FPCAPlot
import skfda.preprocessing.dim_reduction as sk_p
'''

samples = 15696
seq_length = 1300
vars = ["GRFx", "GRFy", "GRFz", "Mx", "My", "Mz", "COPx", "COPy"]

def read_data(var,samples, seq_length):
  dfx = pd.read_csv("/content/drive/MyDrive/ae_data/"+var+".csv", sep=",")[0:samples]
  dfx.set_index("ID", inplace=True)
  fx = dfx.to_numpy().astype(float)[:,0:seq_length]
  return fx

datagx = read_data("GRFx", samples, seq_length)
datagy = read_data("GRFy", samples, seq_length)
datagz = read_data("GRFz", samples, seq_length)

'''
fdgx = skfda.FDataGrid(data_matrix=datagx)
fdgy = skfda.FDataGrid(data_matrix=datagy)
fdgz = skfda.FDataGrid(data_matrix=datagz)

fdgx.plot()
plt.show()

fdgy.plot()
plt.show()

fdgz.plot()
plt.show()
'''

p=797
r=0

plt.plot(np.mean(datagx,axis=0),color = "red")
plt.plot(datagx[p,:])
#plt.plot(datagx[r,:])
plt.show()

plt.plot(np.mean(datagy,axis=0),color = "red")
plt.plot(datagy[p,:])
#plt.plot(datagy[r,:])
plt.show()

plt.plot(np.mean(datagz,axis=0),color = "red")
plt.plot(datagz[p,:])
#plt.plot(datagz[r,:])
plt.show()

